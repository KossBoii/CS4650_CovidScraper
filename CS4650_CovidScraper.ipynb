{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCjJEoYICzYr"
   },
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install newsapi-python\n",
    "!pip install wordcloud\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3Cu20JYDUtn"
   },
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import spacy\n",
    "import pickle\n",
    "\n",
    "API_KEY = '3fce5faf7272425ba4fc57f8d94d5f4e'\n",
    "# nlp_eng = spacy.load(\"en_core_web_sm\")\n",
    "nlp_eng = spacy.load('en_core_web_lg')\n",
    "news_api = NewsApiClient(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8Vh0UZLEr4q",
    "outputId": "462515b8-9dff-4a60-edde-4220ea1fedf1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pageCount = 5\n",
    "totalResult = 0\n",
    "articles=[]\n",
    "\n",
    "for curPage in range(pageCount):\n",
    "  temp = news_api.get_everything(q='coronavirus',\n",
    "                               language='en',\n",
    "                               sort_by='relevancy',\n",
    "                               page=curPage+1)\n",
    "  for item in temp['articles']:\n",
    "    articles.append(item)\n",
    "  totalResult += len(temp['articles'])\n",
    "\n",
    "print('total search results: %d' % totalResult)\n",
    "print(articles)\n",
    "\n",
    "# save the articles dataset using pickle\n",
    "filename = 'articlesCOVID.pckl'\n",
    "pickle.dump(articles, open(filename, 'wb'))\n",
    "\n",
    "filename = 'articlesCOVID.pckl'\n",
    "loaded_articles= pickle.load(open(filename, 'rb'))\n",
    "print(loaded_articles)\n",
    "print(len(loaded_articles))\n",
    "\n",
    "# save the articles dataset with parsed information using pandas\n",
    "data = {\n",
    "    'author': [],\n",
    "    'title': [],\n",
    "    'description': [],\n",
    "    'content': []\n",
    "}\n",
    "for _, article in enumerate(loaded_articles):\n",
    "  author = article['author']\n",
    "  title = article['title']\n",
    "  desc = article['description']\n",
    "  content = article['content']\n",
    "\n",
    "  data['author'].append(author)\n",
    "  data['title'].append(title)\n",
    "  data['description'].append(desc)\n",
    "  data['content'].append(content)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()\n",
    "\n",
    "df.to_excel('covid_articles.xlsx', index = True, header=True)\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLe11Ysj8oaU"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "\n",
    "def get_keywords_eng(text, nlp):\n",
    "  result = []\n",
    "  pos_tag = ['PROPN', 'VERB', 'NOUN'] \n",
    "  doc = nlp(text)\n",
    "  for token in doc:\n",
    "    if token.text in nlp_eng.Defaults.stop_words or token.text in string.punctuation:\n",
    "      continue          # exclude all the STOPWORDS and punctuation from the list\n",
    "    elif token.pos_ in pos_tag:\n",
    "      result.append(token.text)\n",
    "  return result\n",
    "\n",
    "def plot_word_cloud(word_cloud):\n",
    "  plt.figure(figsize=(20,15))\n",
    "  plt.imshow(word_cloud)\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "def generate_word_cloud(articles, type): # type can only be ['title', 'description', 'content']\n",
    "  results = []\n",
    "  \n",
    "  # iterate over 100 results from search\n",
    "  for _, article in enumerate(articles):\n",
    "    item = article[type]\n",
    "    if item is None:\n",
    "      continue\n",
    "    \n",
    "    # get the most common keywords from each article\n",
    "    for keyword in Counter(get_keywords_eng(item, nlp_eng)).most_common(5):\n",
    "      results.append(keyword[0])\n",
    "    \n",
    "  text = ' '.join(results)\n",
    "  wordcloud = WordCloud(max_font_size=50, max_words=100, collocations=False,\n",
    "                      background_color='salmon', colormap='Pastel1').generate(text)       # collocations=False for no duplications\n",
    "  return wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "R6sqNnb1UFaK",
    "outputId": "32fc06b7-6a96-4d12-a09d-26d9b3343348"
   },
   "outputs": [],
   "source": [
    "total_rows = 2\n",
    "total_cols = 2\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "fig, ax = plt.subplots(total_rows, total_cols,figsize=(20, 10))\n",
    "for type in ['title', 'description', 'content']:\n",
    "  # generate WordCloud from articles\n",
    "  wordcloud = generate_word_cloud(articles, type)\n",
    "\n",
    "  # display the WordCloud in the figure\n",
    "  plt.rcParams.update({'font.size': 16})\n",
    "  ax[row][col].imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "  # do not display axis of subplots\n",
    "  ax[row][col].axis('off')\n",
    "\n",
    "  # display title for each subplot\n",
    "  plt.rcParams.update({'font.size': 22})\n",
    "  ax[row][col].set_title('WordCloud for Coronavirus using \\'%s\\'' % type)\n",
    "  plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "  # update subplot position\n",
    "  row = row + 1\n",
    "  if row == total_rows:\n",
    "    row = 0\n",
    "    col = col + 1\n",
    "\n",
    "ax[1][1].axis('off')\n",
    "plt.tight_layout(pad=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS4650_CovidScraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
